\begin{abstract}

\end{abstract}

\subsubsection*{Acknowledgements}

\newpage

\section{Introduction}
\label{sec:intro}

Machine Learning (ML) is a constantly growing field and is essential for many innovative applications such as highly-automated and autonomous driving. Resulting from this,
there is an increased need to maintain security. This thesis concentrates on risk measuring in context of ISO 27001 which will be discussed in \ref{sec:relWork}. Risk
measuring is a part of risk assessment to analyze the system for vulnerabilites. This present thesis evaluates how to measure risks to show where the vulnerabilites are found and what the extent of
damage is by visualizing all results. \\ \\
This thesis explains and discusses a conceptual and technical framework to measure risks which is called Risk-Measurement-Framework (RMF). The RMF will build a conceptual and technical
framework upon approaches by Jakub Breier et al. \cite{DBLP:journals/corr/abs-2012-04884} and Paul Schwerdtner et al. \cite{DBLP:journals/corr/abs-2011-04328}. The core of the RMF is the Adversarial-Robustness-Toolbox (ART) that is included as a Python model but also a open-source framework which will be explained in Section 2.

Sections 1 and 2 are intended to clarify the goals and expectations of this thesis, explain terms, show necessary prior knowledge so that it is well defined where this thesis should go. Section 3 is one of the main parts of the thesis. The section discusses and describes the conceptual framework and gives the basis for the technical framework explained in Section 4. Section 5 explains the case study that uses the framework and shows its potential and how to use it. In Section 6 a conclusion explains possible future work and summary of the results.

\subsection{Motivation}

The classic IT security is a large field and essential for every software application. In ML, security is also essential and needs more tools to find vulnerabilites and measure risks for the subsequent defense implementation. This thesis evaluates a conceptual and technical framework with a common IT security standard. That should improve security in ML and could help researchers and companies to improve and optimize their work. Due to the research for this present thesis there were a lot of scientific papers that did IT security managment in context of ISO 27005 but less with ISO 27004. ML in relation to ISO 27004 is therefore another motivating factor to extend the research in context with security for ML and ISO 27004.

\subsection{Goals and expectations of this present thesis}

\newlist{questions}{enumerate}{2}
\setlist[questions,1]{label=\textsf{\textbf{RQ\arabic*:}},ref=RQ\arabic*}
\setlist[questions,2]{label=(\alph*),ref=\thequestionsi(\alph*)}

\begin{questions}
  \item Which ISO 27004 measurement metrics are useful to measure the risks of poisoning attacks? \label{itm:rq1}
  \item How can the size of a dataset be used to measure the risks of poisoning attacks? \label{itm:rq2}
  \item What are risk indicators of poisoning attacks? \label{itm:rq3}
  \item Which risk indicators can be used for the ML model apart from the dataset? \label{itm:rq4}
  \item How can the effort of an attack be measured? \label{itm:rq5}
  \item Which measurement requirements of ISO 27004 can be used to measure the effort of an attack in ML security? \label{itm:rq6}
  \item Which risk indicators from the poisoning attacks and the attackers effort are useful to evaluate the risks with the RMF? \label{itm:rq7}
  \item What are possible methods in the RMF to measure the effort of an attacker? \label{itm:rq8}
  \item Which backdoor attacks must execute an attacker and objective properties must be fulfilled by the attacker to find how much damage an attacker wants to do with his attack? \label{itm:rq9}
\end{questions}

The first research question \ref{itm:rq1} should introduce the discussion on how to bring the IT security standards in relation with security of ML. This is answered by explaining what ISO 27004 - Risk
Measurement is used for, what poisoning attacks are in ML and how to measure the risks of poisoning attacks in ML with the given standards. \ref{itm:rq2} is intended to define how much impact poisoning
attacks have on data sets based on various variables and how quickly tampering can be detected through risk measurement. The fourth research question \ref{itm:rq4} stands in relation with \ref{itm:rq3} and \ref{itm:rq8} because it could be possible that risk measurement for poisoning attacks and the attackers effort contains risk indicators which used for both. For \ref{itm:rq5} threat models find risk indicators to measure risks of the attackers effort. This indicates the risks of an attacker and how big the extent of damage could come from the attack showed in different ways that are attacks that the attacker has programmed by himself or already finished attacks that are shown by the ART. \ref{itm:rq6} pursues the question which metrics of the ISO 27004 standard can be used to measure risks in relation of the attackers effort. \ref{itm:rq7} is intended to summarize once again how risk indicators can support risk measurement through the framework. The last research question \ref{itm:rq9} is the most important question to show that the framework is able to measure risks and show the extent of damage from all risk indicators.
