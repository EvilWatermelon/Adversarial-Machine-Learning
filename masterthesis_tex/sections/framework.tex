\section{Risk-Measurement-Framework concept and design}
\label{sec:conFrame}

In contrast to Schwerdtner et al., the framework of this thesis concentrates on training, especially risk measurement before and during training of the ML model. The conceptual framework discusses and explains the design of the RMF. The RMF is a technical framework which measures risks of backdoor attacks and measures the attackers effort.

\subsection{Using the standards for the risk measurement}

In ISO/IEC 27004:2009 the requirements how to develop measures and the measurement is specified in the following list:

\begin{enumerate}[label=(\alph*)]
  \item \label{itm:a} ``Defining the measurement scope``
  \item \label{itm:b} ``Identifying an information need``
  \item \label{itm:c} ``Selecting the object of measurement and its attributes``
  \item \label{itm:d} ``Developing measurement constructs``
  \item \label{itm:e} ``Applying measurement constructs``
  \item \label{itm:f} ``Establishing data collection and analysis processes and tools``
  \item \label{itm:g} ``Establishing measurement implementation approach and documentation``
\end{enumerate}

\hfill - in accordance to \cite{ISO_27004_2009} \\

\ref{itm:a} explains that the initial scope of an organization's measurement is based on different elements depending on capabilities and resources on different elements. These are specific controls and their protected information assets  and information security activities. The management must prioritize these. Furthermore, the internal and external stakeholder should be identified which participate on the measurement scope. \\
It is possible that the organization set a limit on the number of measurement results. That should ensure that the decision-makers can improve the ISMS based on the measurement results in a given time interval. The measurement results should be prioritized based on the importance of the corresponding information need. \\ \\
The second point \ref{itm:b} explains that each measurement needs at least one information need. An information need is identified in four activities. At first, the ISMS and its processes must be examined. Then the identified information need must be prioritized based on criteria, such as risk treatment, the organization's capabilities and resources, the interest of stakeholders', and the information security policy. The third activity bases on the list of prioritized information needs where a subset of information is required to be addressed on the measurement activity. The last acitivty is the communcication to the stakeholder of the selected information need. \\
Based on the information needs, the relevant measures should implemented to the ISMS. \\ \\
\ref{itm:c} describes how objects and attributes for the measurement are identified in the scope and context of an ISMS. The relation between the object and attribute is that an object can have several applicable attributes and both are selected by the corresponding information needs. \\
The relevant base measures that are obtained to values are collected by an appropriate measurement method to the attributes that are selected. These selected attributes ensure that an appropriate measurement method and relevant base measures can be identified and the measurement results base on the obtained values and developed measures. The characteristics of selected attributes indentify the type of the measurement method to obtain values that can be assigned with base measures. \\
All of the chosen objects and attributes need to be documented. Objects and attributes that are described by data should be used as values that are assigned to the base measures. The attributes should be checked to ensure that they are appropriate for the measurement and for an effective measurement should the data collection be defined in such a way that sufficient attributes are available. \\ \\
\ref{itm:d} defines the measurement construct development which starts by measure selection than it defines the measurement method, measurement function, the analytical model, indicators, decision criteria, and stakeholders. The measure selection should be defined in sufficient detail for the selection of measures that need to be implemented. If a new measure is implemented it needs to be adapted to an existing measure. Selected measures should represent the information needs priority. Example criteria are, facilitation for data collection, facilitation for interpretation, and measures to calculate costs of analysing, and collecting the data. The third part of \ref{itm:d} explains how to define the measurement method for each measure. That measurement method will be used to quantify the measurement object by transforming the attributes into the value that is assigned to the base measure. Further, the measurement method can be subjective or objective. Subjective methods rely on human judgment and objective base on numerical rules. In the measurement method, the attributes are quantified as values. These value are applied by an appropriate scale while each scale uses measurement units. Each measurement methods verification process must be  \\ \\
\ref{itm:e} \\ \\
\ref{itm:f} \\ \\
\ref{itm:g} \\ \\

\subsubsection*{Derivate the standards for the RMF}

After the explained measures and measurement development based on ISO 27004, the next step is to map requirements into the RMF. This discussion what parts of them can be fulfilled and which parts can not fulfilled. That should show the process of risk measurement in the RMF.

\subsection{Characteristics of backdoor attacks}

After discussing and evaluating the standards for the risk measurement in the RMF this subsection explain how the risks of backdoor attacks are measured.

\subsection{Types of backdoor attacks}

The following backdoor attacks should represent what they can achieve when using them. Further, this subsection should show the basis of the backdoor attacks that are used in the RMF.

\subsubsection*{The theory behind the ART backdoor attacks}

\textit{PoisoningAttackBackdoor} and \textit{PoisoningAttackCleanLabelBackdoor} are the two backdoor attacks in the framework. Gu et al. \cite{DBLP:journals/corr/abs-1708-06733} explain \textit{PoisoningAttackBackdoor} attacks. The goal of this backdoor attack is to change their labels to a target label. This happens by attacking a random small selection of the training set and apply a backdoor trigger into the inputs \cite{turner2018clean}. Gu et al. show in their work different backdoor attacks and do a case study with a traffic sign detection attack. In their work, Gu et al. developed a neural network with a backdoor trigger. The evaluated backdoors are a single pixel backdoor and a pattern backdoor. The single pixel backdoor increase the brightness of a pixel and the pattern backdoor adds a pattern of bright pixels in an image. The implemented attacks from Gu et al. are Single Target attack and an All-to-All attack. Single Target attack use the single pixel backdoor by changing a label from a digit $i$ as a digit $j$. Gu et al. explained that the test data are not available for the attacker. The error rate for their Convolutional Neural Network (CNN) is 0.05\%. The error rate with the backdoored images increases at most to 0.09\%. An All-to-All attack change a digit label $i$ to $i + 1$. After testing the All-to-All attack the originial ML have a error rate of 0.03\% while the ML with the backdoored image have an average error of 0.56\%. \\
In their work, Turner et al. \cite{turner2018clean} explain
\textit{PoisoningAttackCleanLabelBackdoor} attacks. Turner et al. show an approach for executing backdoor attacks by utilizing adversarial examples and GAN-generated data. The point where Turner et al. start is analyzing effectiveness of Gu et al. attack while a simple technique is applied for data filtering. Turner et al. discovered that the poisoned inputs are outliers and are clearly wrong from the human inspection side. The attack would be ineffective if its rely solely on poisoned inputs which are labeled correctly and evade such filtering. At this point Turner et al. created an approach that do poisoned inputs which appear plausible to humans. The inputs need small changes to make them harder while classify them but the original label must still remain plausible. This transformation is performed by a GAN-based interpolation and adversarial bounded pertubations. GAN-based interpolation takes each input into the GAN latent space \cite{DBLP:conf/nips/GoodfellowPMXWOCB14} and then interpolate poisoned samples to an incorrect class. Adversarial bounded pertubations uses a maximization method to maximize the loss of the pre-trained ML model on poisoned inputs while staying around the original input.

\subsubsection*{Additional backdoor attacks to increase the possible extent of damage}


\subsection{Finding the attacker's effort}

Subsection \ref{sec:threat} explained a formal threat model to find the attackers effort with high-level and low-level attributes where the low-level attributes are mapped to with the high-level attributes. At first this subsection will discuss which of the characteristics are useful to find the attackers effort for attacking a ML model. Regarding to the mapping between the attributes, the low-level attributes will be discussed at first.

\subsection{Using the formal threat model}

For the risk measurement the attacker's effort is important to evaluate how high or low the risk is for an ML model. In this subsection the research questions \ref{itm:rq5}, \ref{itm:rq6} are addressed in more detail. In reference to the research question \ref{itm:rq8} this threat model could be a possible method for the RMF to measure risks which will be proved in Section \ref{sec:evaluation}.

\subsubsection*{The low-level attributes}

To find the attacker's effort there is a need to collect data which can be measured from every attack on a ML model. These data is classified and explained in Subsection \ref{sec:threat}. Doynikova et al. explained which data is required to meausre the low-level attributes.

\begin{enumerate}
  \item The first requirement is a dataset which contains information about the attack actions against a ML model. The information must be based on the skills, resources, intention, and motivation of the attacker.
  \item The second requirment for the dataset is that everything is marked in such a way that the analysis shows which actions the attacker performed. But this requirement is more about having multiple attackers or the analysis accross multiple attackers.
\end{enumerate}

\subsubsection*{The high-level attributes}


\subsubsection*{Mapping the low-level with the high-level attributes}


\subsubsection*{Derivate the properties to machine learning}


\subsection{Risk indicators}
\label{sec:risk_indicators}

The RMF measure risks by so called risk indicators. Properties, threat models and proposals are the basis for the risk indicators. Breier et al. in subsection \ref{sec:approaches} present
proposals that are the approach for the proposals of the risk indicators. Doynikova et al. presents a formal threat model to find the attackers effort.

\subsubsection*{Properties, proposals and characteristics derived from classic IT security}


\subsubsection*{Correlations of the properties, proposals and characteristics}


\subsection{Evaluation methods for the measured risks}


\subsubsection*{Analyze the dataset for vulnerabilites}


\subsubsection*{Logging the execution of the attack}


\subsubsection*{Machine learning metrics for risk measurement}


\subsubsection*{Python plots}


\subsubsection*{Calculate the risks}
