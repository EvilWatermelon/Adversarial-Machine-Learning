% !TEX root = C:\Users\Jan\Documents\dev\Risk-Measurement-Framework\masterthesis_tex\masterthesis_main.tex
\section{Introduction}
\label{sec:intro}

Machine Learning (ML) is a constantly growing field and is essential for many innovative applications such as highly-automated and autonomous driving. Resulting from this,
there is an increased need to maintain security. This thesis concentrates on risk measuring in context of common standards like ISO/IEC 27004:2009 - Risk Measurement which will be
discussed in Section \ref{sec:relWork}. Risk measurement is a part of risk assessment to analyze the system for vulnerabilities. This present thesis evaluates how to measure risks and what the
extent of damage is by visualizing all results. \\ \\
This thesis explains and discusses the design of a conceptual framework and its implementation to measure risks which is called Risk-Measurement-Framework (RMF). The RMF is designed by a
conceptual framework based on risk indicators as a fundamental part upon approaches by Jakub Breier et al. \cite{DBLP:journals/corr/abs-2012-04884} and Paul Schwerdtner et al.
\cite{DBLP:journals/corr/abs-2011-04328}. The core of the implementation of the RMF is the Adversarial-Robustness-Toolbox (ART) that is included as a Python library but also an open-source
framework which will be explained in Section 2.

Sections 1 and 2 are intended to clarify the goals and expectations of this thesis, explain terms, show necessary prior knowledge so that it is well defined where this thesis should go.
Section 3 is one of the main parts of the thesis. The section discusses and describes the conceptual framework and gives the basis for the technical framework explained in Section 4.
Section 5 explains the case study that uses the framework and shows its potential and how to use it. In Section 6, a conclusion points out possible future work and summarizes the results.

\subsection{Motivation}

The classic IT security is a large field and essential for every software application. In ML, security is also essential and needs more tools to find vulnerabilites and measure risks for
the subsequent defense implementation. This thesis evaluates a conceptual and technical framework in the context of IT security standards. The aim is to improve security in ML, which could
help researchers and companies to optimize their work. Due to the research for this present thesis, there were a lot of scientific papers that evaluate IT security management in the
context of ISO 27005 but less with ISO 27004. Therefore, there is a need to put more focus on ISO 27004. So ML in relation to ISO 27004 is another motivating factor to extend the research
in the context of security for ML and ISO 27004. From the previously mentioned points, it should emerge that this thesis should show the possibility of using common standards for risk
measurement in ML.

\subsection{Research questions and hypotheses for this thesis}

\newlist{questions}{enumerate}{2}
\setlist[questions,1]{label=\textsf{\textbf{RQ\arabic*:}},ref=RQ\arabic*}
\setlist[questions,2]{label=(\alph*),ref=\thequestionsi(\alph*)}

To understand the goal of this thesis the following hypotheses and research questions should show what this thesis is concentrating about.

\subsubsection*{Research questions}

\begin{questions}
  \item How can the procedure and requirements from ISO 27004 be used for risk measurement of ML models? \label{itm:rq1}
  \item What are risk indicators to measure the extent of damage? \label{itm:rq2}
  \item What are risk indicators to measure the attacker's effort? \label{itm:rq3}
  \item Which measurement methods are suitable for measuring the extent of the damage and the attacker's effort? \label{itm:rq4}
  \item How are the results of a risk presented? \label{itm:rq5}
\end{questions}

\subsubsection*{Hypotheses}

In this thesis, the hypotheses represent assertions that have to be tested.

\newlist{hypotheses}{enumerate}{2}
\setlist[hypotheses,1]{label=\textsf{\textbf{H\arabic*:}},ref=H\arabic*}
\setlist[hypotheses,2]{label=(\alph*),ref=\thehypothesesi(\alph*)}

\begin{hypotheses}
  \item There are several risk indicators to measure the extent of damage when attacking a ML model: \textbf{(a)} attack time \textbf{(b)} attack specificity \textbf{(c)} true positive (TP), true negative (TN), false positive (FP), false negative (FN). \label{itm:h1}
  \item There are several risk indicators to measure the attacker's effort when attacking a ML model: \textbf{(a)} computational resources \textbf{(b)} attacker's goal \textbf{(c)} attacker's knowledge. \label{itm:h2}
  \item It is possible to design and implement a risk measurement framework for ML models based on the generalized requirements of ISO 27004. \label{itm:h3}
  \item The attacker's effort corresponds to the probability of occurrence when calculating the risk. \label{itm:h4}
\end{hypotheses}
