% !TEX root = C:\Users\Jan\Documents\dev\Risk-Measurement-Framework\masterthesis_tex\masterthesis_main.tex
\section{Introduction}
\label{sec:intro}

Machine Learning (ML) is a constantly growing field and is essential for many innovative applications such as highly-automated and autonomous driving. Resulting from this,
there is an increased need to maintain security. This thesis concentrates on risk measuring in context of common standards like ISO/IEC 27004:2009 - Risk Measurement which will be
discussed in Section \ref{sec:relWork}. Risk measurement is a part of risk assessment to analyze the system for vulnerabilities. This present thesis evaluates how to measure risks and what the
extent of damage is by visualizing all results. \\ \\
This thesis explains and discusses the design of a conceptual framework and its implementation to measure risks which is called Risk-Measurement-Framework (RMF). The RMF is designed by a
conceptual framework based on risk indicators as a fundamental part upon approaches by Jakub Breier et al. \cite{DBLP:journals/corr/abs-2012-04884} and Paul Schwerdtner et al.
\cite{DBLP:journals/corr/abs-2011-04328}. The core of the implementation of the RMF is the Adversarial-Robustness-Toolbox (ART) that is included as a Python library but also an open-source
framework which will be explained in Section 2.

Sections 1 and 2 are intended to clarify the goals and expectations of this thesis, explain terms, show necessary prior knowledge so that it is well defined where this thesis should go.
Section 3 is one of the main parts of the thesis. The section discusses and describes the conceptual framework and gives the basis for the technical framework explained in Section 4.
Section 5 explains the case study that uses the framework and shows its potential and how to use it. In Section 6, a conclusion points out possible future work and summarizes the results.

\subsection{Motivation}

The classic IT security is a large field and essential for every software application. In ML, security is also essential and needs more tools to find vulnerabilites and measure risks for
the subsequent defense implementation. This thesis evaluates a conceptual and technical framework in the context of IT security standards. The aim is to improve security in ML, which could
help researchers and companies to optimize their work. Due to the research for this present thesis, there were a lot of scientific papers that evaluate IT security management in the
context of ISO 27005 but less with ISO 27004. Therefore, there is a need to put more focus on ISO 27004. So ML in relation to ISO 27004 is another motivating factor to extend the research
in the context of security for ML and ISO 27004. From the previously mentioned points, it should emerge that this thesis should show the possibility of using common standards for risk
measurement in ML.

\subsection{Research questions and hypotheses for this thesis}

\newlist{questions}{enumerate}{2}
\setlist[questions,1]{label=\textsf{\textbf{RQ\arabic*:}},ref=RQ\arabic*}
\setlist[questions,2]{label=(\alph*),ref=\thequestionsi(\alph*)}

To understand the goal of this thesis the following hypotheses and research questions should show what this thesis is concentrating about.

\subsubsection*{Research questions}

\begin{questions}
  \item How can the procedure and requirements from ISO 27004 be used for risk measurement at ML? \label{itm:rq1}
  \item Which requirements of ISO 27004 can be met by the RMF and which cannot? \label{itm:rq2}
  \item How can the training data be used to measure risks of poisoning attacks, especially backdoor attacks? \label{itm:rq3}
  \item What are risk indicators to measure poisoning attacks, especially backdoor attacks? \label{itm:rq4}
  \item What are risk indicators to measure the attacker's effort? \label{itm:rq5}
  \item How do the values of the risk indicators change before and after an attack on the ML model? \label{itm:rq6}
  \item What measurement methods need to be implemented in the RMF to measure and evaluate risks for backdoor attacks and the effort of an attack? \label{itm:rq7}
  \item Which attacks reflect an appropriate level of damage to mirror a real attack? \label{itm:rq8}
  \item Which risk indicators can be usefully evaluated in combination to obtain the best possible results from risk measurement? \label{itm:rq9}
\end{questions}

Based on these questions, the goals of this thesis are defined. Research question \ref{itm:rq1} is about the extent to which an already known standard can be used to implement measurements in the field of ML security. Research question \ref{itm:rq2} follows from the first research question and is intended to clarify in more detail which requirements can be fulfilled by the RMF. The third research question \ref{itm:rq3} goes more towards concrete risk measurement and at its core is more about training data and how it should contribute to risk measurement. Research question \ref{itm:rq4} and \ref{itm:rq5} are prior to the actual risk measurement and on the basis of these research questions, it should be explained which risk indicators help to get the best possible measurement results. With research question \ref{itm:rq6}, the thesis should address how the risk indicators help to perform risk measurement. With research question \ref{itm:rq7}, the goal is to find suitable measurement methods. The 8th research question \ref{itm:rq8} focuses on the attacks for the risk measurement. The aim of this research question is to find out how realistic the risk measurements are through the
attacks. The last research question \ref{itm:rq9} relates to the evaluation after the risk measurement and from which risk indicators the expected results arise.

\subsubsection*{Hypotheses}

\newlist{hypotheses}{enumerate}{2}
\setlist[hypotheses,1]{label=\textsf{\textbf{H\arabic*:}},ref=H\arabic*}
\setlist[hypotheses,2]{label=(\alph*),ref=\thehypothesesi(\alph*)}

\begin{hypotheses}
  \item The computational resources to implement and execute an attack are a risk indicator to measure the attacker's effort. \label{itm:h1}
  \item The attacker's goal (denial-of-service, obtain secret information, or create an inference failure) is a risk indicator to measure the attacker's effort. \label{itm:h2}
  \item The attacker's knowledge is a risk indicator to show how much effort he must make to attack a ML model. \label{itm:h3}
  \item The single values such as true positive, false positive, ture negative, and false negative to calculate the accuracy are a risk indicator to measure the extent of damage. \label{itm:h4}
  \item The attack specificity is a risk indicator to measure the extent of damage. \label{itm:h5}
  \item The attack time is a risk indicator to measure the extent of damage. \label{itm:h6}
  \item It is possible to design and implement an risk measurement framework for ML models based on the generalized requirements of ISO 27004. \label{itm:h7}
\end{hypotheses}
