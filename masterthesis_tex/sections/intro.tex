% !TEX root = C:\Users\Jan\Documents\dev\Risk-Measurement-Framework\masterthesis_tex\masterthesis_main.tex
\section{Introduction}
\label{sec:intro}

Machine Learning (ML) is a constantly growing field and is essential for many innovative applications such as highly-automated and autonomous driving. Resulting from this,
there is an increased need to maintain security. This thesis concentrates on risk measuring in context of common standards like ISO/IEC 27004:2009 - Risk Measurement which will be
discussed in Section \ref{sec:relWork}. Risk measurement is a part of risk assessment to analyze the system for vulnerabilities. This present thesis evaluates how to measure risks and what the
extent of damage is by visualizing all results. \\ \\
This thesis explains and discusses the design of a conceptual framework and its implementation to measure risks which is called Risk-Measurement-Framework (RMF). The RMF is designed by a
conceptual framework based on risk indicators as a fundamental part upon approaches by Jakub Breier et al. \cite{DBLP:journals/corr/abs-2012-04884} and Paul Schwerdtner et al.
\cite{DBLP:journals/corr/abs-2011-04328}. The core of the implementation of the RMF is the Adversarial-Robustness-Toolbox (ART) that is included as a Python library but also an open-source
framework which will be explained in Section 2.

Sections 1 and 2 are intended to clarify the goals and expectations of this thesis, explain terms, show necessary prior knowledge so that it is well defined where this thesis should go.
Section 3 is one of the main parts of the thesis. The section discusses and describes the conceptual framework and gives the basis for the technical framework explained in Section 4.
Section 5 explains the case study that uses the framework and shows its potential and how to use it. In Section 6, a conclusion points out possible future work and summarizes the results.

\subsection{Motivation}

The classic IT security is a large field and essential for every software application. In ML, security is also essential and needs more tools to find vulnerabilites and measure risks for
the subsequent defense implementation. This thesis evaluates a conceptual and technical framework in the context of IT security standards. The aim is to improve security in ML, which could
help researchers and companies to optimize their work. Due to the research for this present thesis, there were a lot of scientific papers that evaluate IT security management in the
context of ISO 27005 but less with ISO 27004. Therefore, there is a need to put more focus on ISO 27004. So ML in relation to ISO 27004 is another motivating factor to extend the research
in the context of security for ML and ISO 27004. From the previously mentioned points, it should emerge that this thesis should show the possibility of using common standards for risk
measurement in ML.

\subsection{Research questions and hypotheses for this thesis}

\newlist{questions}{enumerate}{2}
\setlist[questions,1]{label=\textsf{\textbf{RQ\arabic*:}},ref=RQ\arabic*}
\setlist[questions,2]{label=(\alph*),ref=\thequestionsi(\alph*)}

To understand the goal of this thesis the following hypotheses and research questions should show what this thesis is concentrating about.

\subsubsection*{Research questions}

\begin{questions}
  \item How can ISO 27004 be used to measure risks in machine learning? \label{itm:rq1}
  \item How can the size of a dataset be used to measure the risks of poisoning attacks? \label{itm:rq2}
  \item What are risk indicators of poisoning attacks? \label{itm:rq3}
  \item Which risk indicators can be used for the ML model apart from the dataset? \label{itm:rq4}
  \item How can the effort of an attack be measured? \label{itm:rq5}
  \item Which measurement requirements of ISO 27004 can be used to measure the effort of an attack in ML security? \label{itm:rq6}
  \item Which risk indicators from the poisoning attacks and the attackers effort are useful to evaluate the risks with the RMF? \label{itm:rq7}
  \item What are possible methods in the RMF to measure the effort of an attacker? \label{itm:rq8}
  \item Which backdoor attacks must execute an attacker and objective properties must be fulfilled by the attacker to find how much damage an attacker wants to do with his attack? \label{itm:rq9}
\end{questions}

\subsubsection*{Hypotheses}

\newlist{hypotheses}{enumerate}{2}
\setlist[hypotheses,1]{label=\textsf{\textbf{H\arabic*:}},ref=H\arabic*}
\setlist[hypotheses,2]{label=(\alph*),ref=\thehypothesesi(\alph*)}

\begin{hypotheses}
  \item The computational resources to implement and execute an attack are a risk indicator to measure the attacker's effort. \label{itm:h1}
  \item The attacker's goal is a risk indicator to measure the attacker's effort. \label{itm:h2}
  \item The attacker's knowledge is a risk indicator to show how much effort he must make to attack a ML model. \label{itm:h3}
  \item The single values such as true positive, false positive, ture negative, and false negative to calculate the accuracy are a risk indicator to measure the extent of damage. \label{itm:h4}
  \item The attack specificity is a risk indicator to measure the extent of damage. \label{itm:h5}
  \item The attack time is a risk indicator to measure the extent of damage. \label{itm:h6}
  \item The general requirements from the ISO 27004 make it possible to design and implement an risk measurement framework for ML models. \label{itm:h7}
\end{hypotheses}
